{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba891f11-1660-4fa0-a0f5-55f66f3cb5ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Function calling using Foundation Model APIs\n",
    "\n",
    "This notebook demonstrates how the *function calling* (or *tool use*) API can be used to extract structured information from natural language inputs using the large language models (LLMs) made available using Foundation Model APIs. This notebook uses the OpenAI SDK to demonstrate interoperability.\n",
    "\n",
    "\n",
    "LLMs generate output in natural language, the exact structure of which is hard to predict even when the LLM is given precise instructions. Function calling forces the LLM to adhere to a strict schema, making it easy to automatically parse the LLM's outputs. This unlocks advanced use cases, enabling LLMs to be components in complex data processing pipelines and Agent workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "147a369f-f071-42f0-af90-1a8ef7d6c443",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3ad22ca-d7ab-4c63-bc2b-b9e2ed0c19b6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install libraries used in this demo"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade openai tenacity tqdm\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "241be99f-a98c-498b-8a78-5fffcdea746d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./_resources/00-init\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e335035c-6398-4356-81b3-bffd7966f722",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Select model endpoint"
    }
   },
   "outputs": [],
   "source": [
    "# The endpoint ID of the model to use. Not all endpoints support function calling.\n",
    "MODEL_ENDPOINT_ID = \"databricks-meta-llama-3-3-70b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1749b5fc-4b86-44e7-9e67-0d9a7f622cd2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set up API client"
    }
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import pandas as pd\n",
    "from openai import OpenAI, RateLimitError\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    "    retry_if_exception,\n",
    ")  # for exponential backoff\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "# A token and the workspace's base FMAPI URL are needed to talk to endpoints\n",
    "fmapi_token = (\n",
    "    dbutils.notebook.entry_point.getDbutils()\n",
    "    .notebook()\n",
    "    .getContext()\n",
    "    .apiToken()\n",
    "    .getOrElse(None)\n",
    ")\n",
    "fmapi_base_url = (\n",
    "    f'https://{spark.conf.get(\"spark.databricks.workspaceUrl\")}/serving-endpoints'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d1814dd-a697-4972-bfaf-4f6fae2821c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "The following defines helper functions that assist the LLM to respond according to the specified schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "83ad266e-5640-4332-a354-591a264d5d15",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set up helper functions"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "openai_client = OpenAI(api_key=fmapi_token, base_url=fmapi_base_url)\n",
    "\n",
    "\n",
    "# NOTE: We *strongly* recommend handling retry errors with backoffs, so your code gracefully degrades when it bumps up against pay-per-token rate limits.\n",
    "@retry(\n",
    "    wait=wait_random_exponential(min=1, max=30),\n",
    "    stop=stop_after_attempt(3),\n",
    "    retry=retry_if_exception(RateLimitError),\n",
    ")\n",
    "\n",
    "def call_chat_model(\n",
    "    prompt: str, temperature: float = 0.0, max_tokens: int = 100, **kwargs\n",
    "):\n",
    "    \"\"\"Calls the chat model and returns the response text or tool calls.\"\"\"\n",
    "    chat_args = {\n",
    "        \"model\": MODEL_ENDPOINT_ID,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "    }\n",
    "    chat_args.update(kwargs)\n",
    "\n",
    "    try:\n",
    "        chat_completion = openai_client.chat.completions.create(**chat_args)\n",
    "        response = chat_completion.choices[0].message\n",
    "\n",
    "        if response.tool_calls:\n",
    "            call_args = [c.function.arguments for c in response.tool_calls]\n",
    "            if len(call_args) == 1:\n",
    "                return call_args[0]\n",
    "            return call_args\n",
    "        \n",
    "        return response.content  \n",
    "    except Exception as e:\n",
    "        # print(f\"Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "def call_in_parallel(func, prompts: List[str]) -> List:\n",
    "    \"\"\"Calls func(p) for all prompts in parallel and returns responses.\"\"\"\n",
    "    # This uses a relatively small thread pool to avoid triggering default workspace rate limits.\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = []\n",
    "        for r in tqdm(executor.map(func, prompts), total=len(prompts)):\n",
    "            results.append(r)\n",
    "        return results\n",
    "\n",
    "\n",
    "def results_to_dataframe(units: List[str], responses: List[str]):\n",
    "    \"\"\"Combines reviews and model responses into a dataframe for tabular display.\"\"\"\n",
    "    return pd.DataFrame({\"Units\": units, \"Model response\": responses})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "eae4ff83-3fd9-4b08-815b-28ade4cc77ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Example: Taxonomy Consolidation\n",
    "This section demonstrates a few increasingly reliable approaches for consolidating taxonomy descriptions:\n",
    "* **Unstructured (least reliable)**: Basic prompting. Relies on the model to generate valid JSON on its own.\n",
    "* **Tool schema**: Augment prompt with a tool schema, guiding the model to adhere to that schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "76169db0-107f-42ac-908b-c2d84479b653",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog = catalog\n",
    "schema = db\n",
    "table_name = \"raw_supplier_dummy_data\"\n",
    "                     \n",
    "# Read the DataFrame to Unity Catalog as a Delta table\n",
    "table_path = f\"{catalog}.{schema}.{table_name}\"\n",
    "clean_df = spark.table(table_path)\n",
    "display(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf935649-414c-4dde-8323-f1e470247c82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "delivery_unit_name_list = clean_df.select(\"DELIVERY_UNIT_NAME\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "49faf994-b7ab-463b-97c6-aabf67c7426f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Unstructured generation\n",
    "Given a unit name, the most obvious strategy is to instruct the model to generate a JSON that looks like this: `{\"label\": \"UNIT_A\"}`.\n",
    "\n",
    "This approach mostly works with models like DBRX and Llama-3-70B. However, sometimes models generate extraneous text such as, \"helpful\" comments about the task or input.\n",
    "\n",
    "Prompt engineering can refine performance. For example, SHOUTING instructions at the model is a popular strategy. But if you use this strategy you must validate the output to detect and disregard nonconformant outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f076b80-64ee-4199-9137-ff6823fa6287",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "Imagine you are trying to consolidate the delivery unit names that can have many variations. Your task is to map the delivery unit {unit} to one of the following categories:\n",
    "[\n",
    "    \"Logistics Unit 1\",\n",
    "    \"Supply Team A\",\n",
    "    \"Delivery Group North\",\n",
    "    \"Central Distribution Team\",\n",
    "    \"East Logistics Hub\",\n",
    "    \"West End Delivery\",\n",
    "    \"Urban Supply Group\",\n",
    "    \"Rural Delivery Unit\",\n",
    "    \"Coastal Logistics\",\n",
    "    \"City Centre Distribution\",\n",
    "    \"North Delivery Hub\",\n",
    "    \"Midlands Logistics Team\",\n",
    "    \"Southwest Supply Group\",\n",
    "    \"Northwest Distribution\",\n",
    "    \"London Logistics Unit\",\n",
    "    \"Southern Delivery Squad\",\n",
    "    \"East Coast Dispatch\",\n",
    "    \"Regional Delivery Team A\",\n",
    "    \"Western Supply Chain\",\n",
    "    \"Inner City Logistics\",\n",
    "    \"Central Midlands Delivery\",\n",
    "    \"Remote Area Delivery\",\n",
    "    \"Urban Hub Logistics\",\n",
    "    \"Express Delivery Unit\",\n",
    "    \"Northern Distribution Centre\",\n",
    "    \"Route B Supply Team\",\n",
    "    \"West Midlands Distribution\",\n",
    "    \"East End Logistics\",\n",
    "    \"Metro Delivery Unit\",\n",
    "    \"Capital Logistics\",\n",
    "    \"Suburban Supply Group\",\n",
    "    \"Greater London Dispatch\",\n",
    "    \"Outer Ring Logistics\",\n",
    "    \"Highlands Delivery Team\",\n",
    "    \"Valley Supply Unit\",\n",
    "    \"Central Hub Dispatch\",\n",
    "    \"Rural Network Logistics\",\n",
    "    \"West Coast Delivery\",\n",
    "    \"Supply Chain Express\",\n",
    "    \"South Logistics Unit\",\n",
    "    \"Northeast Distribution Team\",\n",
    "    \"South Delivery Hub\",\n",
    "    \"East Midlands Supply\",\n",
    "    \"London Central Dispatch\",\n",
    "    \"Island Delivery Group\",\n",
    "    \"Regional Logistics Unit B\",\n",
    "    \"Express Route Distribution\",\n",
    "    \"City Zone Logistics\",\n",
    "    \"Outskirt Delivery Unit\",\n",
    "    \"Central District Supply\"\n",
    "]\n",
    "*Do no answer with None\n",
    "*Must find the closest label to the input\n",
    "return Your output in json format. Do not add extra text\n",
    "\"\"\"\n",
    "\n",
    "def prompt_with_outlier_tool(delivery_unit_name_list: List[str]):\n",
    "    # Convert the list of products to a string format suitable for the LLM\n",
    "    units_str = \"\\n\".join(delivery_unit_name_list)\n",
    "    prompt = PROMPT_TEMPLATE.format(unit=units_str)\n",
    "    return call_chat_model(prompt)\n",
    "\n",
    "results = call_in_parallel(prompt_with_outlier_tool, delivery_unit_name_list)\n",
    "\n",
    "results_df = results_to_dataframe(delivery_unit_name_list, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4970137c-d600-4078-9df8-d3f4a4f90b51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6281ae3c-1df9-46e5-bf70-8fe6ec2cfe8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Classifying with tools\n",
    "Output quality can be improved by using the `tools` API. You can provide a strict JSON schema for the output, and the FMAPI inference service ensures that the model's output either adheres to this schema or returns an error if this is not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7b3ee4f-c708-42da-a7a6-4de9fb4b5642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE_UPDATED = \"\"\"\n",
    "Imagine you are trying to consolidate the delivery unit names that can have many variations. Your task is to map the delivery unit {unit} to one category\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b161269-4202-45a5-951f-d8661e65f9e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"_taxonomy_consolidation\",\n",
    "            \"description\": \"Consolidate the taxonomy of delivery units\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"Logistics Unit 1\",\n",
    "                                \"Supply Team A\",\n",
    "                                \"Delivery Group North\",\n",
    "                                \"Central Distribution Team\",\n",
    "                                \"East Logistics Hub\",\n",
    "                                \"West End Delivery\",\n",
    "                                \"Urban Supply Group\",\n",
    "                                \"Rural Delivery Unit\",\n",
    "                                \"Coastal Logistics\",\n",
    "                                \"City Centre Distribution\",\n",
    "                                \"North Delivery Hub\",\n",
    "                                \"Midlands Logistics Team\",\n",
    "                                \"Southwest Supply Group\",\n",
    "                                \"Northwest Distribution\",\n",
    "                                \"London Logistics Unit\",\n",
    "                                \"Southern Delivery Squad\",\n",
    "                                \"East Coast Dispatch\",\n",
    "                                \"Regional Delivery Team A\",\n",
    "                                \"Western Supply Chain\",\n",
    "                                \"Inner City Logistics\",\n",
    "                                \"Central Midlands Delivery\",\n",
    "                                \"Remote Area Delivery\",\n",
    "                                \"Urban Hub Logistics\",\n",
    "                                \"Express Delivery Unit\",\n",
    "                                \"Northern Distribution Centre\",\n",
    "                                \"Route B Supply Team\",\n",
    "                                \"West Midlands Distribution\",\n",
    "                                \"East End Logistics\",\n",
    "                                \"Metro Delivery Unit\",\n",
    "                                \"Capital Logistics\",\n",
    "                                \"Suburban Supply Group\",\n",
    "                                \"Greater London Dispatch\",\n",
    "                                \"Outer Ring Logistics\",\n",
    "                                \"Highlands Delivery Team\",\n",
    "                                \"Valley Supply Unit\",\n",
    "                                \"Central Hub Dispatch\",\n",
    "                                \"Rural Network Logistics\",\n",
    "                                \"West Coast Delivery\",\n",
    "                                \"Supply Chain Express\",\n",
    "                                \"South Logistics Unit\",\n",
    "                                \"Northeast Distribution Team\",\n",
    "                                \"South Delivery Hub\",\n",
    "                                \"East Midlands Supply\",\n",
    "                                \"London Central Dispatch\",\n",
    "                                \"Island Delivery Group\",\n",
    "                                \"Regional Logistics Unit B\",\n",
    "                                \"Express Route Distribution\",\n",
    "                                \"City Zone Logistics\",\n",
    "                                \"Outskirt Delivery Unit\",\n",
    "                                \"Central District Supply\"]               \n",
    "                    }\n",
    "                },  # This closing brace was missing\n",
    "                \"required\": [\"unit\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "def prompt_with_tool(delivery_unit_name_list: List[str]):\n",
    "    # Convert the list of products to a string format suitable for the LLM\n",
    "    units_str = \"\\n\".join(delivery_unit_name_list)\n",
    "    prompt = PROMPT_TEMPLATE.format(unit=units_str)\n",
    "    return call_chat_model(prompt, tools=tools)\n",
    "\n",
    "results = call_in_parallel(prompt_with_tool, delivery_unit_name_list)\n",
    "\n",
    "tagged_df=results_to_dataframe(delivery_unit_name_list, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b5198bb-6b9b-4b66-a6c0-238c461bc3e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(tagged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e9c140f-213c-4f28-ae4b-b30d89a8d5fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2,
    "sqlDataframeCounter": 0
   },
   "notebookName": "4. LLM Extraction",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
